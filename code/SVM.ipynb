{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(37)\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing\n",
    "# Att: You're not allowed to use modules other than SVC in sklearn, i.e., model_selection.\n",
    "\n",
    "# Dataset information\n",
    "# the column names (names of the features) in the data files\n",
    "# you can use this information to preprocess the features\n",
    "col_names_x = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status',\n",
    "             'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss',\n",
    "             'hours-per-week', 'native-country']\n",
    "col_names_y = ['label']\n",
    "\n",
    "numerical_cols = ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss',\n",
    "                  'hours-per-week']\n",
    "categorical_cols = ['workclass', 'education', 'marital-status', 'occupation', 'relationship',\n",
    "                    'race', 'sex', 'native-country']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38842, 104) (10000, 104)\n"
     ]
    }
   ],
   "source": [
    "# x,y = read_file('../data/salary.labeled.csv')\n",
    "# x.shape,y.shape\n",
    "x,y = load_data(csv_file_path='salary.labeled.csv')\n",
    "# x1,y = load_data(csv_file_path='salary.2Predict.csv')\n",
    "# col1 = x1.columns\n",
    "# col = x.columns\n",
    "# for i in range(len(col1)):\n",
    "#     if col[i] != col1[i]:\n",
    "#         print(col1[i])\n",
    "print(x.shape,x1.shape)\n",
    "# svclassifier = SVC(kernel='rbf', C=1, degree = 1)\n",
    "# svclassifier.fit(x, y)\n",
    "# y_pred = svclassifier.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x,y = load_data(csv_file_path='../salary.labeled.csv')\n",
    "# print(get_acc(y_pred,y))\n",
    "# best_model, best_score = train_and_select_model(training_csv='../salary.labeled.csv')\n",
    "# print(np.sum(x[0]))\n",
    "# print(best_model, best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Data loading from file and pre-processing.\n",
    "# Hint: Feel free to use some existing libraries for easier data pre-processing. \n",
    "# For example, as a start you can use one hot encoding for the categorical variables and normalization \n",
    "# for the continuous variables.\n",
    "def load_data(csv_file_path):\n",
    "    # your code here\n",
    "    file = open(csv_file_path)\n",
    "    df = pd.read_csv(csv_file_path,\n",
    "        header=None,\n",
    "        names=col_names_x+col_names_y\n",
    "       )\n",
    "    # drop the NaN\n",
    "#     df = df.dropna(axis=0, how=\"any\")\n",
    "\n",
    "    y = df['label'].astype('category')\n",
    "    y = y.replace([\" <=50K\", \" >50K\"],[0, 1])\n",
    "    \n",
    "    # dataset has '?' in it, convert these into NaN, then fill NaN with the most frequent value of column\n",
    "    df = df.replace(' ?', np.nan)\n",
    "    df = df.replace(' Holand-Netherlands', np.nan)\n",
    "    x = df.drop('label', axis=1)\n",
    "    x = x.fillna(x.mode().iloc[0])\n",
    "    \n",
    "    #implement one hot encoding for the categorial variables\n",
    "    categorical_ = ['workclass','education','marital-status','occupation','relationship',\n",
    "                'race','sex','native-country'\n",
    "    ]\n",
    "    x = pd.get_dummies(x, columns=categorical_)\n",
    "    \n",
    "    # drop the column that is not in training data\n",
    "#     if csv_file_path == \"salary.2Predict.csv\":\n",
    "#         x = x.drop('native-country_ Holand-Netherlands', axis=1)\n",
    "#     print(\"Partial data\\n\", x.iloc[0:10, :])\n",
    "    \n",
    "    # Normalization\n",
    "    x = preprocessing.StandardScaler().fit_transform(x)\n",
    "#     min_max_scaler = preprocessing.MinMaxScaler(feature_range=(0,1))\n",
    "#     x = min_max_scaler.fit_transform(x)\n",
    "    return x, y.to_numpy()\n",
    "\n",
    "def fold(x, y, i, nfolds):\n",
    "    # your code\n",
    "    width = int(x.shape[0]/nfolds)\n",
    "    x_left, x_test, x_right =  np.split(x,[i*width,(i+1)*width],axis=0)\n",
    "    y_left, y_test, y_right =  np.split(y,[i*width,(i+1)*width],axis=0)\n",
    "    x_train = np.concatenate((x_left,x_right), axis = 0)\n",
    "    y_train = np.concatenate((y_left,y_right), axis = 0)\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "def get_acc(y_pred,y):\n",
    "    correct = 0.0\n",
    "    for i in range(y.shape[0]):\n",
    "        correct += (y_pred[i]==y[i])\n",
    "    return float(correct/len(y))\n",
    "\n",
    "# 2. Select best hyperparameter with cross validation and train model.\n",
    "# Attention: Write your own hyper-parameter candidates.\n",
    "def train_and_select_model(training_csv):\n",
    "    # load data and preprocess from filename training_csv\n",
    "    x, y = load_data(training_csv)\n",
    "    # hard code hyperparameter configurations, an example:\n",
    "    param_set = [\n",
    "                 {'kernel': 'linear', 'C': 1, 'degree': 5},\n",
    "                 {'kernel': 'linear', 'C': 3, 'degree': 5},\n",
    "                 {'kernel': 'rbf', 'C': 1, 'degree': 1},\n",
    "                 {'kernel': 'rbf', 'C': 1, 'degree': 2},\n",
    "                 {'kernel': 'rbf', 'C': 3, 'degree': 2},\n",
    "                 {'kernel': 'rbf', 'C': 5, 'degree': 2},\n",
    "                 {'kernel': 'poly', 'C': 3, 'degree': 2},\n",
    "                 {'kernel': 'poly', 'C': 3, 'degree': 3},\n",
    "                 {'kernel': 'poly', 'C': 1, 'degree': 3},\n",
    "                 {'kernel': 'poly', 'C': 1, 'degree': 2},\n",
    "    ]\n",
    "    best_score = 0.0\n",
    "    accuracys = []\n",
    "    for params in param_set:\n",
    "        val_acc = 0.0\n",
    "        train_acc = 0.0\n",
    "#         print(acc)\n",
    "#         model = SVC(kernel=params['kernel'], C = params['C'], degree = params['degree'])\n",
    "        for i in range(3):\n",
    "            x_train, y_train, x_test, y_test = fold(x,y,i,3)\n",
    "            model = SVC(kernel=params['kernel'], C = params['C'], degree = params['degree'])\n",
    "            model.fit(x_train, y_train)\n",
    "            y_pred = model.predict(x_test)\n",
    "            y_pred1 = model.predict(x_train)\n",
    "            train_acc += get_acc(y_pred1, y_train)\n",
    "            val_acc += get_acc(y_pred,y_test)\n",
    "#             print(acc)\n",
    "        val_acc /= 3\n",
    "        train_acc /= 3\n",
    "#         print(acc)\n",
    "        print(\"Train acc: \",train_acc,\" \",params)\n",
    "        print(\"Test acc: \",val_acc,\" \",params)\n",
    "#         print(model)\n",
    "        if val_acc > best_score:\n",
    "            best_score = val_acc\n",
    "            best_model = model\n",
    "    # your code here\n",
    "    # iterate over all hyperparameter configurations\n",
    "    # perform 3 FOLD cross validation\n",
    "    # print cv scores for every hyperparameter and include in pdf report\n",
    "    # select best hyperparameter from cv scores, retrain model \n",
    "    return best_model, best_score\n",
    "\n",
    "# predict for data in filename test_csv using trained model\n",
    "def predict(test_csv, trained_model):\n",
    "    x_test, _ = load_data(test_csv)\n",
    "    predictions = trained_model.predict(x_test)\n",
    "    return predictions\n",
    "\n",
    "# save predictions on test data in desired format \n",
    "def output_results(predictions):\n",
    "    with open('predictions.txt', 'w') as f:\n",
    "        for pred in predictions:\n",
    "            if pred == 0:\n",
    "                f.write('<=50K\\n')\n",
    "            else:\n",
    "                f.write('>50K\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc:  0.8504215743064942   {'kernel': 'linear', 'C': 1, 'degree': 5}\n",
      "Test acc:  0.8486908164053449   {'kernel': 'linear', 'C': 1, 'degree': 5}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-f62b465d28fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# cross validation to select hyperparameters as well as cross validation score for best hyperparameter.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# hardcode hyperparameter configurations as part of train_and_select_model(training_csv)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtrained_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_and_select_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_csv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The best model was scored %.2f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mcv_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-dc136d369541>\u001b[0m in \u001b[0;36mtrain_and_select_model\u001b[0;34m(training_csv)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'kernel'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdegree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'degree'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0my_pred1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml3.7/lib/python3.7/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml3.7/lib/python3.7/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    266\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    training_csv = \"salary.labeled.csv\"\n",
    "    testing_csv = \"salary.2Predict.csv\"\n",
    "    # fill in train_and_select_model(training_csv) to \n",
    "    # return a trained model with best hyperparameter from 3-FOLD \n",
    "    # cross validation to select hyperparameters as well as cross validation score for best hyperparameter. \n",
    "    # hardcode hyperparameter configurations as part of train_and_select_model(training_csv)\n",
    "    trained_model, cv_score = train_and_select_model(training_csv)\n",
    "\n",
    "    print(\"The best model was scored %.2f\" % cv_score)\n",
    "    # use trained SVC model to generate predictions\n",
    "    predictions = predict(testing_csv, trained_model)\n",
    "    # Don't archive the files or change the file names for the automated grading.\n",
    "    # Do not shuffle the test dataset\n",
    "    output_results(predictions)\n",
    "    # 3. Upload your Python code, the predictions.txt as well as a report to Collab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc:  0.8503829568127695   {'kernel': 'linear', 'C': 3, 'degree': 1}\n",
      "Test acc:  0.8486393244252207   {'kernel': 'linear', 'C': 3, 'degree': 1}\n",
      "The best model was scored 0.85\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    training_csv = \"salary.labeled.csv\"\n",
    "    testing_csv = \"salary.2Predict.csv\"\n",
    "    # fill in train_and_select_model(training_csv) to \n",
    "    # return a trained model with best hyperparameter from 3-FOLD \n",
    "    # cross validation to select hyperparameters as well as cross validation score for best hyperparameter. \n",
    "    # hardcode hyperparameter configurations as part of train_and_select_model(training_csv)\n",
    "    trained_model, cv_score = train_and_select_model(training_csv)\n",
    "    \n",
    "    filename = 'trained_model.sav'\n",
    "    pickle.dump(trained_model, open(filename, 'wb'))\n",
    "\n",
    "    print(\"The best model was scored %.2f\" % cv_score)\n",
    "    # use trained SVC model to generate predictions\n",
    "    predictions = predict(testing_csv, trained_model)\n",
    "    # Don't archive the files or change the file names for the automated grading.\n",
    "    # Do not shuffle the test dataset\n",
    "    output_results(predictions)\n",
    "    # 3. Upload your Python code, the predictions.txt as well as a report to Collab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuyining/anaconda3/envs/ml3.7/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/liuyining/anaconda3/envs/ml3.7/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/liuyining/anaconda3/envs/ml3.7/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc:  0.8779172298384501   {'kernel': 'rbf', 'C': 5, 'degree': 2}\n",
      "Test acc:  0.8471460570016219   {'kernel': 'rbf', 'C': 5, 'degree': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuyining/anaconda3/envs/ml3.7/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/liuyining/anaconda3/envs/ml3.7/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/liuyining/anaconda3/envs/ml3.7/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc:  0.8632940722147132   {'kernel': 'rbf', 'C': 1, 'degree': 2}\n",
      "Test acc:  0.8480729126438558   {'kernel': 'rbf', 'C': 1, 'degree': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuyining/anaconda3/envs/ml3.7/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/liuyining/anaconda3/envs/ml3.7/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/liuyining/anaconda3/envs/ml3.7/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc:  0.8566776082898887   {'kernel': 'poly', 'C': 3, 'degree': 2}\n",
      "Test acc:  0.8355603614737004   {'kernel': 'poly', 'C': 3, 'degree': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuyining/anaconda3/envs/ml3.7/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/liuyining/anaconda3/envs/ml3.7/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/liuyining/anaconda3/envs/ml3.7/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc:  0.8545536461350326   {'kernel': 'poly', 'C': 1, 'degree': 3}\n",
      "Test acc:  0.8313895110836488   {'kernel': 'poly', 'C': 1, 'degree': 3}\n",
      "Train acc:  0.8503829568127695   {'kernel': 'linear', 'C': 3, 'degree': 5}\n",
      "Test acc:  0.8486393244252207   {'kernel': 'linear', 'C': 3, 'degree': 5}\n",
      "The best model was scored 0.85\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    training_csv = \"salary.labeled.csv\"\n",
    "    testing_csv = \"salary.2Predict.csv\"\n",
    "    # fill in train_and_select_model(training_csv) to \n",
    "    # return a trained model with best hyperparameter from 3-FOLD \n",
    "    # cross validation to select hyperparameters as well as cross validation score for best hyperparameter. \n",
    "    # hardcode hyperparameter configurations as part of train_and_select_model(training_csv)\n",
    "    trained_model, cv_score = train_and_select_model(training_csv)\n",
    "    \n",
    "    filename = 'trained_model.sav'\n",
    "    pickle.dump(trained_model, open(filename, 'wb'))\n",
    "\n",
    "    print(\"The best model was scored %.2f\" % cv_score)\n",
    "    # use trained SVC model to generate predictions\n",
    "    predictions = predict(testing_csv, trained_model)\n",
    "    # Don't archive the files or change the file names for the automated grading.\n",
    "    # Do not shuffle the test dataset\n",
    "    output_results(predictions)\n",
    "    # 3. Upload your Python code, the predictions.txt as well as a report to Collab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuyining/anaconda3/envs/ml3.7/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/liuyining/anaconda3/envs/ml3.7/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/liuyining/anaconda3/envs/ml3.7/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc:  0.8632940722147132   {'kernel': 'rbf', 'C': 1, 'degree': 1}\n",
      "Test acc:  0.8480729126438558   {'kernel': 'rbf', 'C': 1, 'degree': 1}\n",
      "Train acc:  0.8504215743064942   {'kernel': 'linear', 'C': 1, 'degree': 5}\n",
      "Test acc:  0.8486908164053449   {'kernel': 'linear', 'C': 1, 'degree': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuyining/anaconda3/envs/ml3.7/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/liuyining/anaconda3/envs/ml3.7/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/liuyining/anaconda3/envs/ml3.7/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc:  0.848593679603527   {'kernel': 'poly', 'C': 1, 'degree': 2}\n",
      "Test acc:  0.8334234442985505   {'kernel': 'poly', 'C': 1, 'degree': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liuyining/anaconda3/envs/ml3.7/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/liuyining/anaconda3/envs/ml3.7/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/liuyining/anaconda3/envs/ml3.7/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc:  0.873386110574757   {'kernel': 'rbf', 'C': 3, 'degree': 2}\n",
      "Test acc:  0.8483818645246003   {'kernel': 'rbf', 'C': 3, 'degree': 2}\n",
      "Train acc:  0.8504215743064942   {'kernel': 'linear', 'C': 0.5, 'degree': 2}\n",
      "Test acc:  0.8486135784351587   {'kernel': 'linear', 'C': 0.5, 'degree': 2}\n",
      "Train acc:  0.8504215743064942   {'kernel': 'linear', 'C': 1, 'degree': 7}\n",
      "Test acc:  0.8486908164053449   {'kernel': 'linear', 'C': 1, 'degree': 7}\n",
      "The best model was scored 0.85\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    training_csv = \"salary.labeled.csv\"\n",
    "    testing_csv = \"salary.2Predict.csv\"\n",
    "    # fill in train_and_select_model(training_csv) to \n",
    "    # return a trained model with best hyperparameter from 3-FOLD \n",
    "    # cross validation to select hyperparameters as well as cross validation score for best hyperparameter. \n",
    "    # hardcode hyperparameter configurations as part of train_and_select_model(training_csv)\n",
    "    trained_model, cv_score = train_and_select_model(training_csv)\n",
    "    \n",
    "    filename = 'trained_model.sav'\n",
    "    pickle.dump(trained_model, open(filename, 'wb'))\n",
    "\n",
    "    print(\"The best model was scored %.2f\" % cv_score)\n",
    "    # use trained SVC model to generate predictions\n",
    "    predictions = predict(testing_csv, trained_model)\n",
    "    # Don't archive the files or change the file names for the automated grading.\n",
    "    # Do not shuffle the test dataset\n",
    "    output_results(predictions)\n",
    "    # 3. Upload your Python code, the predictions.txt as well as a report to Collab."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml3.7",
   "language": "python",
   "name": "ml3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
