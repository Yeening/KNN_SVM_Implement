{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting code for UVA CS 4501 Machine Learning- KNN\n",
    "\n",
    "__author__ = 'yl7sr'\n",
    "import numpy as np\n",
    "np.random.seed(37)\n",
    "# for plot\n",
    "import matplotlib.pyplot as plt\n",
    "#more imports\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "## the only purpose of the above import is in case that you want to compare your knn with sklearn knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load file into np arrays\n",
    "# x is the features\n",
    "# y is the labels\n",
    "def read_file(file):\n",
    "    data = np.loadtxt(file, skiprows=1)\n",
    "    np.random.shuffle(data)\n",
    "    x = data[:, :-1]\n",
    "    y = data[:, -1].astype(int)\n",
    "    return x, y\n",
    "\n",
    "\n",
    "# 2. Generate the i-th fold of k fold validation\n",
    "# Input:\n",
    "# x is an np array for training data\n",
    "# y is an np array for labels\n",
    "# i is an int indicating current fold\n",
    "# nfolds is the total number of cross validation folds\n",
    "def fold(x, y, i, nfolds):\n",
    "    # your code\n",
    "    width = int(x.shape[0]/nfolds)\n",
    "    x_left, x_test, x_right =  np.split(x,[i*width,(i+1)*width],axis=0)\n",
    "    y_left, y_test, y_right =  np.split(y,[i*width,(i+1)*width],axis=0)\n",
    "    x_train = np.concatenate((x_left,x_right), axis = 0)\n",
    "    y_train = np.concatenate((y_left,y_right), axis = 0)\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "\n",
    "# 3. Classify each testing points based on the training points\n",
    "# Input\n",
    "# x_train: a numpy array of training data \n",
    "# x_test: a numpy array\n",
    "# k: the number of neighbors to take into account when predicting the label\n",
    "# Output\n",
    "# y_predict: a numpy array \n",
    "def classify(x_train, y_train, x_test, k):\n",
    "    # your code\n",
    "    # Euclidean distance as the measurement of distance in KNN\n",
    "    # Build the distance matrix\n",
    "    y_predict = np.zeros((len(x_test)),dtype = int)\n",
    "    for i in range(len(x_test)):\n",
    "        dis_line = np.zeros((len(x_train)),dtype=float)\n",
    "        for j in range(len(x_train)):\n",
    "            dis_line[j] = distance(x_test[i],x_train[j])\n",
    "        dis_line = np.concatenate((dis_line.reshape(-1,1),y_train.reshape(-1,1)),axis=1)\n",
    "        copy = dis_line.copy()\n",
    "        #sort the 2d array by the first cloumn\n",
    "        copy = copy[copy[:,0].argsort()]\n",
    "        vote = 0\n",
    "        for j in range(k):\n",
    "            if copy[j][1] == 1:\n",
    "                vote += 1\n",
    "            else:\n",
    "                vote -= 1\n",
    "        y_predict[i] = int(vote > 0)\n",
    "#     print(y_predict)\n",
    "    return y_predict\n",
    "\n",
    "def distance(p1, p2):\n",
    "    return np.sqrt(np.sum(np.power(p1-p2,2)))\n",
    "\n",
    "# 4. Calculate accuracy by comaring with true labels\n",
    "# Input\n",
    "# y_predict is a numpy array of 1s and 0s for the class prediction\n",
    "# y is a numpy array of 1s and 0s for the true class label\n",
    "def calc_accuracy(y_predict, y):\n",
    "    # your code\n",
    "    total = y_predict.shape[0]\n",
    "    correct = 0\n",
    "    for i in range(total):\n",
    "        if y_predict[i] == y[i]: correct += 1\n",
    "    acc = float(correct/total)\n",
    "    return acc\n",
    "\n",
    "# 1. Find the best K\n",
    "def findBestK(x, y, klist, nfolds):\n",
    "    kbest = 0\n",
    "    best_acc = 0\n",
    "    accuracy_list = []\n",
    "    for k in klist:\n",
    "        # your code here\n",
    "        # to get nfolds cross validation accuracy for k neighbors\n",
    "        # implement fold(x, y, i, nfolds),classify(x_train, y_train, x_test, k) and calc_accuracy(y_predict, y)\n",
    "        accuracy = 0.0\n",
    "        for i in range(nfolds):\n",
    "            x_train, y_train, x_test, y_test = fold(x,y,i,nfolds)\n",
    "            y_predict = classify(x_train, y_train, x_test, k)\n",
    "            accuracy += calc_accuracy(y_predict, y_test)\n",
    "        accuracy /= nfolds # CROSS VALIDATION accuracy for k neighbors\n",
    "        if accuracy > best_acc:\n",
    "            kbest = k\n",
    "            best_acc = accuracy\n",
    "        accuracy_list.append(accuracy)\n",
    "        print(k, accuracy)\n",
    "    # plot cross validation error for each k : implement function barplot(klist, accuracy_list)\n",
    "    barplot(klist, accuracy_list)\n",
    "    return kbest\n",
    "\n",
    "# 5. Draw the bar plot of k vs. accuracy\n",
    "# klist: a list of values of ks\n",
    "# accuracy_list: a list of accuracies\n",
    "def barplot(klist, accuracy_list):\n",
    "    # your code\n",
    "    # use matplot lib to generate bar plot with K on x axis and cross validation accuracy on y-axis\n",
    "#     fig, ax = plt.subplots()\n",
    "    plt.bar(klist, accuracy_list,width = 0.35)\n",
    "#     plt.xticks(klist, ('Bill', 'Fred', 'Mary', 'Sue'))\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 0.6004999999999999\n",
      "5 0.6094999999999999\n",
      "7 0.624\n",
      "9 0.6075\n",
      "11 0.6115\n",
      "13 0.616\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best K is:  7\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    filename = \"Movie_Review_Data.txt\"\n",
    "    # read data\n",
    "    x, y = read_file(filename)\n",
    "    nfolds = 4\n",
    "    klist = [3, 5, 7, 9, 11, 13]\n",
    "    # Implementation covers two tasks, both part of findBestK function\n",
    "    # Task 1 : implement kNN classifier for a given x,y,k \n",
    "    # Task 2 : implement 4 fold cross validation to select best k from klist\n",
    "     \n",
    "    bestk = findBestK(x, y, klist, nfolds)\n",
    "    # report best k, and accuracy, discuss why some k work better than others\n",
    "    print(\"Best K is: \", bestk)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml3.7",
   "language": "python",
   "name": "ml3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
